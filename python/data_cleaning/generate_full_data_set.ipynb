{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f6d0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dataclasses\n",
    "from typing import Dict, Optional\n",
    "import more_itertools\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f02396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass(frozen=True)\n",
    "class DataSource:\n",
    "    \"\"\" \n",
    "    A dataset with columns to be renamed to be comibed with other DataSources.\n",
    "    \"\"\"\n",
    "    \n",
    "    data: pd.DataFrame\n",
    "    column_mapping: Dict[str, str] # maps New Column Name -> Old Column Name\n",
    "    name: Optional[str] = None\n",
    "    \n",
    "    def remap(self):\n",
    "        \"\"\"\n",
    "        Rename and select a subset of data columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Values mapped to None mean that value isn't available in the given dataset\n",
    "        rename_dict = {v: k for k, v in self.column_mapping.items() if v is not None}\n",
    "        \n",
    "        df = self.data[rename_dict.keys()]\n",
    "        df = df.rename(columns=rename_dict)\n",
    "        \n",
    "        if self.name is not None: \n",
    "            if \"data_source\" in df.columns:\n",
    "                raise ValueError(\"df already contains data source column.\")\n",
    "            \n",
    "            df[\"data_source\"] = self.name\n",
    "            #df[\"data_source\"] = df[\"data_source\"].astype(\"category\")\n",
    "            \n",
    "        return df\n",
    "    \n",
    "def combine(*data_sources, require_matched_columns: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Concatenate DataSources into a single df.\n",
    "    \"\"\"\n",
    "        \n",
    "    column_names = [s.column_mapping.keys() for s in data_sources]\n",
    "    if require_matched_columns and not more_itertools.all_equal(column_names):\n",
    "        raise ValueError(\"All DataSources must list the same set of new column names.\")\n",
    "        \n",
    "    processed = [data_source.remap() for data_source in data_sources]\n",
    "    result = pd.concat(processed, ignore_index = True)\n",
    "        \n",
    "    if any([s.name for s in data_sources]):\n",
    "        result[\"data_source\"] = result[\"data_source\"].astype(\"category\")\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41d89442",
   "metadata": {},
   "outputs": [],
   "source": [
    "dig_memorial = pd.read_csv(\"https://raw.githubusercontent.com/IndigentBurials/indigent-burials/main/python/web-scraping/oregon-and-dignity-memorial/data/dignity-memorial.csv\").rename(columns=lambda x: x.strip())\n",
    "chicago_burials = pd.read_csv(\"https://raw.githubusercontent.com/IndigentBurials/indigent-burials/main/python/web-scraping/chicago-cookcounty/data/Medical_Examiner_-_Burial_Locations.csv\").rename(columns=lambda x: x.strip())\n",
    "chicago_cremations = pd.read_csv(\"https://raw.githubusercontent.com/IndigentBurials/indigent-burials/main/python/web-scraping/chicago-cookcounty/data/Medical_Examiner_Indigent_Cremations.csv\").rename(columns=lambda x: x.strip())  \n",
    "king_county = pd.read_csv(\"https://raw.githubusercontent.com/IndigentBurials/indigent-burials/main/python/web-scraping/KingCounty/data/KingCounty%20Seattle%20Burial%20Names%20%20-%20Sheet1.csv\").rename(columns=lambda x: x.strip())    \n",
    "bernalillo = pd.read_csv(\"https://raw.githubusercontent.com/IndigentBurials/indigent-burials/main/python/web-scraping/bernalillo-county/data/bernalillo%20county_indigent_unfilters.csv\").rename(columns=lambda x: x.strip())  \n",
    "dona_ana =  pd.read_csv(\"https://raw.githubusercontent.com/IndigentBurials/indigent-burials/main/python/web-scraping/dona-ana-scraping/data/dona-ana-cleaned-v2.csv\").rename(columns=lambda x: x.strip())  \n",
    "fresno = pd.read_csv(\"https://raw.githubusercontent.com/IndigentBurials/indigent-burials/main/python/web-scraping/fresno-scraping/data/fresno-cleaned3-v2.csv\").rename(columns=lambda x: x.strip())  \n",
    "hart_island = pd.read_csv(\"https://raw.githubusercontent.com/IndigentBurials/indigent-burials/main/python/web-scraping/hart-island-web-scraper/data/output/hart-island.csv\").rename(columns=lambda x: x.strip())  \n",
    "la_county = pd.read_csv(\"https://raw.githubusercontent.com/IndigentBurials/indigent-burials/main/python/web-scraping/la-county/data/LA%20Cremation%20Data%20Enhanced.csv\").rename(columns=lambda x: x.strip())  \n",
    "namus = pd.read_csv(\"https://raw.githubusercontent.com/IndigentBurials/indigent-burials/main/python/web-scraping/namus/data/unclaimed_states_combined_cleaned.csv\").rename(columns=lambda x: x.strip())  \n",
    "oregon = pd.read_csv(\"https://raw.githubusercontent.com/IndigentBurials/indigent-burials/main/python/web-scraping/oregon-and-dignity-memorial/data/oregon.csv\").rename(columns=lambda x: x.strip())  \n",
    "yakima_county = pd.read_csv(\"https://raw.githubusercontent.com/IndigentBurials/indigent-burials/main/python/web-scraping/yakima-county/data/Unclaimed%20Remains_Yakima%20County.csv\").rename(columns=lambda x: x.strip())  \n",
    "yellowstone = pd.read_csv(\"https://raw.githubusercontent.com/IndigentBurials/indigent-burials/main/python/web-scraping/yellowstone_mt/Riverside%20Indigent%20Burials%202021.csv\").rename(columns=lambda x: x.strip())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0266c7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNAME</th>\n",
       "      <th>FNAME</th>\n",
       "      <th>MNAME</th>\n",
       "      <th>DOB</th>\n",
       "      <th>DOD</th>\n",
       "      <th>DOI</th>\n",
       "      <th>CEMETERY</th>\n",
       "      <th>CSITEID</th>\n",
       "      <th>CAUSEDEATH</th>\n",
       "      <th>MEMO</th>\n",
       "      <th>...</th>\n",
       "      <th>DOIYR</th>\n",
       "      <th>DOIMON</th>\n",
       "      <th>DOIDAY</th>\n",
       "      <th>PLBIRTH</th>\n",
       "      <th>MSTATUS</th>\n",
       "      <th>TIMEINT</th>\n",
       "      <th>CREMCODE</th>\n",
       "      <th>DISINTERCODE</th>\n",
       "      <th>DEATH_CERT_NUM</th>\n",
       "      <th>LastModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buirge</td>\n",
       "      <td>Barbara</td>\n",
       "      <td>W</td>\n",
       "      <td>5/2/04</td>\n",
       "      <td>5/3/94</td>\n",
       "      <td>5/23/18</td>\n",
       "      <td>RIV</td>\n",
       "      <td>RIV_7_L_17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Princeton, MO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10:00:AM</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Howell</td>\n",
       "      <td>Charles</td>\n",
       "      <td>Olan</td>\n",
       "      <td>8/13/46</td>\n",
       "      <td>11/16/11</td>\n",
       "      <td>5/23/18</td>\n",
       "      <td>RIV</td>\n",
       "      <td>RIV_7_M_17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Baltimore ME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10:00 AM</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hughes</td>\n",
       "      <td>Mary</td>\n",
       "      <td>Jane</td>\n",
       "      <td>1/4/27</td>\n",
       "      <td>2/13/82</td>\n",
       "      <td>5/23/18</td>\n",
       "      <td>RIV</td>\n",
       "      <td>RIV_7_A_16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Crawford, NE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linville</td>\n",
       "      <td>Miriam</td>\n",
       "      <td>E</td>\n",
       "      <td>8/30/07</td>\n",
       "      <td>7/23/81</td>\n",
       "      <td>5/23/18</td>\n",
       "      <td>RIV</td>\n",
       "      <td>RIV_7_B_16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Boone, IA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10:00 AM</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milliken</td>\n",
       "      <td>Gail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/5/19</td>\n",
       "      <td>12/23/87</td>\n",
       "      <td>5/23/18</td>\n",
       "      <td>RIV</td>\n",
       "      <td>RIV_7_C_16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10:00 AM</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Muniyan</td>\n",
       "      <td>Mark</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>2/9/78</td>\n",
       "      <td>11/27/19</td>\n",
       "      <td>5/19/21</td>\n",
       "      <td>RIV</td>\n",
       "      <td>RIV_7_K_12</td>\n",
       "      <td>Suicide</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1114879.0</td>\n",
       "      <td>11:39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Mirko</td>\n",
       "      <td>Joan</td>\n",
       "      <td>E</td>\n",
       "      <td>2/3/43</td>\n",
       "      <td>1/31/21</td>\n",
       "      <td>5/19/21</td>\n",
       "      <td>RIV</td>\n",
       "      <td>RIV_7_J_12</td>\n",
       "      <td>Natural causes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Long Beach, CA</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1230903.0</td>\n",
       "      <td>12:13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Arcena</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/18/48</td>\n",
       "      <td>8/3/20</td>\n",
       "      <td>5/19/21</td>\n",
       "      <td>RIV</td>\n",
       "      <td>RIV_7_H_12</td>\n",
       "      <td>Natural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1176513.0</td>\n",
       "      <td>17:36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Price</td>\n",
       "      <td>Darcy</td>\n",
       "      <td>Lea</td>\n",
       "      <td>4/22/20</td>\n",
       "      <td>7/31/60</td>\n",
       "      <td>5/19/21</td>\n",
       "      <td>RIV</td>\n",
       "      <td>RIV_7_G_12</td>\n",
       "      <td>Natural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Virginia, MN</td>\n",
       "      <td>Married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1186240.0</td>\n",
       "      <td>18:38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Brooks</td>\n",
       "      <td>Sherry</td>\n",
       "      <td>Lynn</td>\n",
       "      <td>8/28/61</td>\n",
       "      <td>4/12/21</td>\n",
       "      <td>5/19/21</td>\n",
       "      <td>RIV</td>\n",
       "      <td>RIV_7_I_12</td>\n",
       "      <td>Natural causes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Moundville, AL</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1247183.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        LNAME    FNAME    MNAME      DOB       DOD      DOI CEMETERY  \\\n",
       "0      Buirge  Barbara        W   5/2/04    5/3/94  5/23/18      RIV   \n",
       "1      Howell  Charles     Olan  8/13/46  11/16/11  5/23/18      RIV   \n",
       "2      Hughes     Mary     Jane   1/4/27   2/13/82  5/23/18      RIV   \n",
       "3    Linville   Miriam        E  8/30/07   7/23/81  5/23/18      RIV   \n",
       "4    Milliken     Gail      NaN   2/5/19  12/23/87  5/23/18      RIV   \n",
       "..        ...      ...      ...      ...       ...      ...      ...   \n",
       "120   Muniyan     Mark  Anthony   2/9/78  11/27/19  5/19/21      RIV   \n",
       "121     Mirko     Joan        E   2/3/43   1/31/21  5/19/21      RIV   \n",
       "122    Arcena   Thomas      NaN  8/18/48    8/3/20  5/19/21      RIV   \n",
       "123     Price    Darcy      Lea  4/22/20   7/31/60  5/19/21      RIV   \n",
       "124    Brooks   Sherry     Lynn  8/28/61   4/12/21  5/19/21      RIV   \n",
       "\n",
       "        CSITEID      CAUSEDEATH MEMO  ...   DOIYR DOIMON DOIDAY  \\\n",
       "0    RIV_7_L_17             NaN  NaN  ...  2018.0    5.0   23.0   \n",
       "1    RIV_7_M_17             NaN  NaN  ...  2018.0    5.0   23.0   \n",
       "2    RIV_7_A_16             NaN  NaN  ...  2018.0    5.0   23.0   \n",
       "3    RIV_7_B_16             NaN  NaN  ...  2018.0    5.0   23.0   \n",
       "4    RIV_7_C_16             NaN  NaN  ...  2018.0    5.0   23.0   \n",
       "..          ...             ...  ...  ...     ...    ...    ...   \n",
       "120  RIV_7_K_12         Suicide  NaN  ...  2021.0    5.0   19.0   \n",
       "121  RIV_7_J_12  Natural causes  NaN  ...  2021.0    5.0   19.0   \n",
       "122  RIV_7_H_12         Natural  NaN  ...  2021.0    5.0   19.0   \n",
       "123  RIV_7_G_12         Natural  NaN  ...  2021.0    5.0   19.0   \n",
       "124  RIV_7_I_12  Natural causes  NaN  ...  2021.0    5.0   19.0   \n",
       "\n",
       "            PLBIRTH   MSTATUS   TIMEINT  CREMCODE  DISINTERCODE  \\\n",
       "0     Princeton, MO       NaN  10:00:AM         x           NaN   \n",
       "1      Baltimore ME       NaN  10:00 AM         x           NaN   \n",
       "2      Crawford, NE       NaN  10:00 AM       NaN           NaN   \n",
       "3         Boone, IA       NaN  10:00 AM         x           NaN   \n",
       "4               NaN       NaN  10:00 AM         x           NaN   \n",
       "..              ...       ...       ...       ...           ...   \n",
       "120          Alaska    Single       NaN       NaN           NaN   \n",
       "121  Long Beach, CA  Divorced       NaN       NaN           NaN   \n",
       "122   San Diego, CA  Divorced       NaN       NaN           NaN   \n",
       "123    Virginia, MN   Married       NaN       NaN           NaN   \n",
       "124  Moundville, AL    Single       NaN       NaN           NaN   \n",
       "\n",
       "     DEATH_CERT_NUM  LastModifiedDate  \n",
       "0               NaN               NaN  \n",
       "1               NaN               NaN  \n",
       "2               NaN               NaN  \n",
       "3               NaN               NaN  \n",
       "4               NaN               NaN  \n",
       "..              ...               ...  \n",
       "120       1114879.0           11:39.0  \n",
       "121       1230903.0           12:13.0  \n",
       "122       1176513.0           17:36.0  \n",
       "123       1186240.0           18:38.0  \n",
       "124       1247183.0               NaN  \n",
       "\n",
       "[125 rows x 33 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellowstone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2185e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _map_yellowstone(df: pd.DataFrame):\n",
    "    df[\"LastModified\"] = date.today()\n",
    "    df[\"State\"] = \"Montana\"\n",
    "    df[\"Jurisdiction\"] = \"Riverside County\"\n",
    "    \n",
    "    df_dict = {\n",
    "        \"Lname\": \"LNAME\",\n",
    "        \"Fname\": \"FNAME\",\n",
    "        \"MName\": \"MNAME\",\n",
    "        \"DOB\": \"DOB\",\n",
    "        \"DOD\": \"DOD\",\n",
    "        \"DB\": \"DOI\",\n",
    "        \"Cemet\"\n",
    "    }\n",
    "\n",
    "def _map_yakima_county(df: pd.DataFrame):\n",
    "    df[\"LastModified\"] = date.today()\n",
    "    df[\"State\"] = \"Washington\"\n",
    "    df[\"Jurisdiction\"] = \"Yakima County\"\n",
    "    df[\"SourceURL\"] = \"https://dhs.lacounty.gov/home-public-resources-locate-deceased-persons/\"\n",
    "    \n",
    "    df_dict = {\n",
    "        \"LName\": \"Last Name\",\n",
    "        \"FName\": \"First Name\",\n",
    "        \"MName\": \"Middle Name\",\n",
    "        \"DOB\": \"DOB:\",\n",
    "        \"DOD\": \"DOD:\",\n",
    "        \"State\": \"State\",\n",
    "        \"SourceURL\": \"SourceURL\",\n",
    "        \"Jurisdiction\": \"Jurisdiction\",\n",
    "        \"LastModified\": \"LastModified\",\n",
    "    }\n",
    "    return df_dict\n",
    "\n",
    "def _map_oregon(df: pd.DataFrame):\n",
    "    df[\"LastModified\"] = date.today()\n",
    "    df[\"State\"] = \"Oregon\"\n",
    "    \n",
    "    df_dict = {\n",
    "        \"LName\": \"Last Name\",\n",
    "        \"FName\": \"First Name\",\n",
    "        \"MName\": \"Middle Name\",\n",
    "        \"BD\": \"Buried\",\n",
    "        \"State\": \"State\",\n",
    "        \"SourceURL\": \"Source URL\",\n",
    "        \"Jurisdiction\": \"Jurisdicition\",\n",
    "        \"LastModified\": \"LastModified\",\n",
    "    }\n",
    "    return df_dict\n",
    "\n",
    "def _map_namus(df: pd.DataFrame):\n",
    "    df[\"LastModified\"] = date.today()\n",
    "    \n",
    "    df_dict = {\n",
    "        \"LName\": \"Last Name\",\n",
    "        \"FName\": \"First Name\",\n",
    "        \"DOD\": \"DBF\",\n",
    "        \"RaceEthnicity\": \"Race/Ethnicity\",\n",
    "        \"Sex\": \"Sex\",\n",
    "        \"City\": \"City\",\n",
    "        \"County\": \"County\",\n",
    "        \"State\": \"State\",\n",
    "        \"SourceURL\": \"Source URL\",\n",
    "        \"Jurisdiction\": \"Jurisdicition\",\n",
    "        \"LastModified\": \"LastModified\",\n",
    "    }\n",
    "    return df_dict\n",
    "\n",
    "def _map_la_county(df: pd.DataFrame):\n",
    "    df[\"LastModified\"] = date.today()\n",
    "    \n",
    "    df_dict = {\n",
    "        \"LName\": \"Last.Ne\",\n",
    "        \"FName\": \"First.Ne\",\n",
    "        \"MName\": \"Middle.Ne\",\n",
    "        \"BD\": \"Date.of.Cremation..mm.dd.yyyy.\",\n",
    "        \"SourceURL\": \"Source URL\",\n",
    "        \"Jurisdiction\": \"Jurisdiction\",\n",
    "        \"LastModified\": \"LastModified\",\n",
    "    }\n",
    "    return df_dict\n",
    "\n",
    "def _map_hart_island(df: pd.DataFrame):\n",
    "    df[\"LastModified\"] = date.today()\n",
    "    \n",
    "    df_dict = {\n",
    "        \"LName\": \"LName\",\n",
    "        \"FName\": \"FName\",\n",
    "        \"DOD\": \"DOD\",\n",
    "        \"Age\": \"Age\",\n",
    "        \"Sex\": \"Sex\",\n",
    "        \"SourceURL\": \"SourceURL\",\n",
    "        \"Jurisdiction\": \"Jurisdiction\",\n",
    "        \"LastModified\": \"LastModified\",\n",
    "    }\n",
    "    return df_dict\n",
    "\n",
    "def _map_fresno(df: pd.DataFrame):\n",
    "    df[\"LastModified\"] = date.today()\n",
    "    \n",
    "    df_dict = {\n",
    "        \"LName\": \"Last Name\",\n",
    "        \"FName\": \"First Name\",\n",
    "        \"MName\": \"Middle Name\",\n",
    "        \"DOB\": \"DOB\",\n",
    "        \"DOD\": \"DOD\",\n",
    "        \"Age\": \"Age\",\n",
    "        \"Sex\": \"Sex\",\n",
    "        \"SourceURL\": \"Source URL\",\n",
    "        \"Jurisdiction\": \"Jurisdiction\",\n",
    "        \"LastModified\": \"LastModified\",\n",
    "    }\n",
    "    return df_dict\n",
    "\n",
    "def _map_dona_ana(df: pd.DataFrame):\n",
    "    df[\"LastModified\"] = date.today()\n",
    "    \n",
    "    df_dict = {\n",
    "        \"LName\": \"Last Name\",\n",
    "        \"FName\": \"First Name\",\n",
    "        \"MName\": \"Middle Name\",\n",
    "        \"DOB\": \"DOB\",\n",
    "        \"DOD\": \"DOD\",\n",
    "        \"Age\": \"Age\",\n",
    "        \"SourceURL\": \"Source URL\",\n",
    "        \"Jurisdiction\": \"Jurisdiction\",\n",
    "        \"LastModified\": \"LastModified\",\n",
    "    }\n",
    "    return df_dict\n",
    "\n",
    "def _map_bernalillo(df: pd.DataFrame):\n",
    "    df[\"Jurisdiction\"] = \"Bernalill0\"\n",
    "    df[\"LastModified\"] = date.today()\n",
    "    df[\"isVeteran\"] = df[\"Veteran\"].replace({\"Yes\": 1, \"No\": 0})\n",
    "    \n",
    "    df_dict = {\n",
    "        \"LName\": \"Last Name\",\n",
    "        \"FName\": \"First Name\",\n",
    "        \"MName\": \"Middle Name\",\n",
    "        \"OName\": \"Maiden Name\",\n",
    "        \"DOB\": \"Date of Birth\",\n",
    "        \"DOD\": \"Date of Death\",\n",
    "        \"BD\": \"Cremation Date\",\n",
    "        \"isVeteran\": \"isVeteran\",\n",
    "        \"MilitaryAffiliation\": \"Military Branch\",\n",
    "        \"Jurisdiction\": \"Jurisdiction\",\n",
    "        \"LastModified\": \"LastModified\",\n",
    "    }\n",
    "    return df_dict\n",
    "\n",
    "def _map_king_county(df: pd.DataFrame):\n",
    "    df[\"Jurisdiction\"] = \"King County\"\n",
    "    df[\"LastModified\"] = date.today()\n",
    "    \n",
    "    df_dict = {\n",
    "        \"LName\": \"Last Name\",\n",
    "        \"FName\": \"First Name\",\n",
    "        \"MName\": \"Middle Name\",\n",
    "        \"BD\": \"Year of Burial\",\n",
    "        \"SourceURL\": \"Source URL\",\n",
    "        \"Jurisdiction\": \"Jurisdiction\",\n",
    "        \"LastModified\": \"LastModified\",\n",
    "    }\n",
    "    \n",
    "    return df_dict\n",
    "\n",
    "def _map_chicago_cremations(df: pd.DataFrame):\n",
    "    df[\"Jurisdiction\"] = \"Chicago, Cook County\"\n",
    "    df[\"LastModified\"] = date.today()\n",
    "    \n",
    "    df_dict = {\n",
    "        \"LName\": \"LastName\",\n",
    "        \"FName\": \"Name\",\n",
    "        \"MName\": \"MiddleName\",\n",
    "        \"Age\": \"Age\",\n",
    "        \"Sex\": \"Sex\",\n",
    "        \"RaceEthnicity\": \"Race\",\n",
    "        \"BD\": \"Cremation Date\",\n",
    "        \"DOD\": \"Date of Death\",\n",
    "        \"SourceURL\": \"SourceURL\",\n",
    "        \"Jurisdiction\": \"Jurisdiction\",\n",
    "        \"LastModified\": \"LastModified\",\n",
    "    }\n",
    "        \n",
    "    return df_dict\n",
    "\n",
    "def _map_dignity_memorial(df: pd.DataFrame):\n",
    "    df[\"isVeteran\"] = 1\n",
    "    df[\"LastModified\"] = date.today()\n",
    "    df[\"DOB\"] = pd.to_datetime(df[\"DOB\"], utc=True, errors='coerce').dt.date\n",
    "        \n",
    "    df_dict = {\n",
    "        \"LName\": \"Last Name\",\n",
    "        \"FName\": \"First Name\",\n",
    "        \"MName\": \"Middle Name\",\n",
    "        \"DOB\": \"DOB\",\n",
    "        \"DOD\": \"DOD\",\n",
    "        \"Jurisdiction\": \"Jurisdicition\",\n",
    "        \"SourceURL\": \"Source URL\",\n",
    "        \"DateScraped\": \"Date Scraped\",\n",
    "        \"LastModified\": \"LastModified\",\n",
    "        \"isVeteran\": \"isVeteran\",\n",
    "        \"MilitaryAffiliation\": \"Department Of Defense\"\n",
    "    }\n",
    "    \n",
    "    return df_dict\n",
    "\n",
    "def _map_chicago_burials(df: pd.DataFrame):\n",
    "    df[\"Jurisdiction\"] = \"Chicago, Cook County\"\n",
    "    df[\"LastModified\"] = date.today()\n",
    "    \n",
    "    df_dict = {\n",
    "        \"LName\": \"LastName\",\n",
    "        \"FName\": \"FirstName\",\n",
    "        \"MName\": \"MiddleName\",\n",
    "        \"Age\": \"Age\",\n",
    "        \"Sex\": \"Sex\",\n",
    "        \"RaceEthnicity\": \"Race\",\n",
    "        \"BD\": \"Burial Date\",\n",
    "        \"DOD\": \"Date of Death\",\n",
    "        \"Jurisdiction\": \"Jurisdiction\",\n",
    "        \"LastModified\": \"LastModified\",\n",
    "    }\n",
    "        \n",
    "    return df_dict\n",
    "            \n",
    "def _map_yakima_county(df: pd.DataFrame):\n",
    "    df[\"LastModified\"] = date.today()\n",
    "    df[\"State\"] = \"Washington\"\n",
    "    df[\"Jurisdiction\"] = \"Yakima County\"\n",
    "    df[\"SourceURL\"] = \"https://dhs.lacounty.gov/home-public-resources-locate-deceased-persons/\"\n",
    "    \n",
    "    df_dict = {\n",
    "        \"LName\": \"Last Name\",\n",
    "        \"FName\": \"First Name\",\n",
    "        \"MName\": \"Middle Name\",\n",
    "        \"DOB\": \"DOB:\",\n",
    "        \"DOD\": \"DOD:\",\n",
    "        \"State\": \"State\",\n",
    "        \"SourceURL\": \"SourceURL\",\n",
    "        \"Jurisdiction\": \"Jurisdiction\",\n",
    "        \"LastModified\": \"LastModified\",\n",
    "    }\n",
    "    return df_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91ffe5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dig_memorial_dict = _map_dignity_memorial(dig_memorial)\n",
    "chicago_burials_dict = _map_chicago_burials(chicago_burials)\n",
    "chicago_cremations_dict =  _map_chicago_cremations(chicago_cremations)\n",
    "king_county_dict = _map_king_county(king_county)\n",
    "bernalillo_dict = _map_bernalillo(bernalillo)\n",
    "dona_ana_dict = _map_dona_ana(dona_ana)\n",
    "fresno_dict = _map_fresno(fresno)\n",
    "hart_island_dict = _map_hart_island(hart_island)\n",
    "la_county_dict = _map_la_county(la_county)\n",
    "namus_dict = _map_namus(namus)\n",
    "oregon_dict = _map_oregon(oregon)\n",
    "yakima_county_dict = _map_yakima_county(yakima_county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22c8ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combine(\n",
    "        DataSource(dig_memorial, dig_memorial_dict, \"Dignity Memorial\"),\n",
    "        DataSource(chicago_burials, chicago_burials_dict, \"Chicago Burials\"),\n",
    "        DataSource(chicago_cremations, chicago_cremations_dict, \"Chicago Cremations\"),\n",
    "        DataSource(king_county, king_county_dict, \"King County\"),\n",
    "        DataSource(bernalillo, bernalillo_dict, \"Bernalillo\"),\n",
    "        DataSource(dona_ana, dona_ana_dict, \"Dona Ana\"),\n",
    "        DataSource(fresno, fresno_dict, \"Fresno\"),\n",
    "        DataSource(hart_island, hart_island_dict, \"Hart Island\"),\n",
    "        DataSource(la_county, la_county_dict, \"LA County\"),\n",
    "        DataSource(namus, namus_dict, \"National\"),\n",
    "        DataSource(oregon, oregon_dict, \"Oregon\"),\n",
    "        DataSource(yakima_county, yakima_county_dict, \"Yakima County\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69ae285b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"datetime.date\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m combined_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/celiahealy/Documents/GitHub/indigent-burials/python/data/indigent_burials_main.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m archive_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/celiahealy/Documents/GitHub/indigent-burials/python/data/archive/indigent_burials_main_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoday\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"datetime.date\") to str"
     ]
    }
   ],
   "source": [
    "combined_df.to_csv(\"/Users/celiahealy/Documents/GitHub/indigent-burials/python/data/indigent_burials_main.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f28ad9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "date_path = today.strftime(\"%Y_%m_%d\")\n",
    "archive_path = \"/Users/celiahealy/Documents/GitHub/indigent-burials/python/data/archive/indigent_burials_main_\"\n",
    "save_path = archive_path + date_path + \".csv\"\n",
    "combined_df.to_csv(save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
